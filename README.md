## Hotel Reservation Data Preprocessing and Analysis
This project entails comprehensive preprocessing and analysis of hotel reservation data,
with a meticulous examination of diverse neural network parameters to enhance prediction
accuracy for booking forecasts.

## Project Description
The main objective of this project is to improve the accuracy of hotel booking predictions
using deep learning techniques. A detailed analysis of hotel reservation data will be conducted
to identify patterns and trends, and various neural network hyperparameters will be explored to
optimize model performance.

Repository Structure
The repository is organized as follows:

data/: Folder containing the hotel reservation data (raw, preprocessed and target).
notebooks/: Folder containing Jupyter notebooks used for data preprocessing, analysis, and modeling.
report.pdf: Document containing the explanation of the neural network building. It also includes the analysis of the different hyperparameters of the network.
requirements.txt: File listing all project dependencies for easy environment installation.

### Analyzed Hyperparameters
To improve the accuracy of hotel booking predictions, the following neural network hyperparameters will be analyzed and adjusted:

- Number of Hidden Layers: Different configurations of hidden layers will be tested to determine the most suitable architecture for the problem.
- Number of Neurons per Layer: The number of neurons in each layer will be adjusted to find the balance between model representation capacity and generalization.
- Activation Functions: Various activation functions, such as ReLU, tanh, and sigmoid, will be experimented with to evaluate their impact on model performance.
- Learning Rate: The optimizer's learning rate will be adjusted to control the model's convergence speed.
- Regularization Techniques: Techniques such as L1/L2 regularization and dropout will be explored to prevent overfitting and improve generalization.
- Initialization Techniques: Different weight initialization methods, including random initialization, Xavier initialization, and He initialization, will be tested to set initial weights effectively.
- Optimization Algorithms: Various optimization algorithms, such as SGD, Adam, and RMSprop, will be compared to find the most efficient approach for training the model.
